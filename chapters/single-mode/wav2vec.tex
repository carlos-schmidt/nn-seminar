The wav2vec2.0 model by Facebook AI~\cite{wav2vec20} consists of a CNN + transformer architecture. The CNN takes as input raw audio data and outputs latent speech representations. These representations are on the one hand quantized and used as pseudo labels for the training procedure. On the other hand they are input into the transformer network, which in turn outputs contextualized representations. Then, a contrastive loss is applied to different parts of the transformer's outputs, after masking said outputs. This means, a combination of contrastive, generative and predictive learning is applied. The goal is to maximize the similarity between the contextualized representations and the localized representations.