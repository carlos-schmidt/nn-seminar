1. Motivation for self supervised learning / What is self supervised learning in general. Where does it maybe originate from?\\
With the rise of deep learning, the use of labeled data to train models capable of \dots
HOW TO INTRO?~WITHOUT USING WORDS OF~\cite{srl-review}?

One example of labeled speech data is paired audio-text data, which consists of pairs of voice tracks and corresponding text segments. These kind of data can for example be used to train end-to-end automatic speech representation (ASR) models.\\Human-labeled speech data is expensive and generally of limited supply, especially so for languages with comparatively few speakers in the world.\\This is why methods using only unlabeled speech data were developed and are since being used to tackle many natural language processing tasks such as the aforementioned ASR task~\cite{unsupervised_learning}.

Self-supervised learning comprises of \enquote{techniques that utilize information extracted from the input data itself as the label to learn representations useful
for downstream tasks.}~\cite{srl-review}\\
2. Bridge to speech/natural language processing\\
3. Pre-training. Generative Learning. Contrastive Learning. Predictive Learning.