% What is speech representation learning
The goal of learning intermediate latent representations of a given input instead of learning an explicit task end-to-end is to be able to extract information out of the input and use this information to tackle multiple tasks. Speech representations are latent representation of speech input. This input could be in formats such as raw waveform, or mel filterbank features. Speech representations are related to (textual) semantic word embeddings as these embeddings are also latent representations with extracted information, in that case their semantic relatedness~\cite{glove}. The difference from textual embeddings to speech representations and what makes learning speech representations hard is that spoken words don't have clear boundaries, speech input is continuous as opposed to discrete textual words and that speech contains more information than text like for example speaker information, noise or emotion.
% History
The first attempts at learning speech representations were done using clustering algorithms like k-means or Gaussian Mixture Models~\cite{clustering} and later improved by adding Hidden Markov Models to allow processing of continuous speech rather than single words~\cite{HMMs}. Currently, the prevalent approach for learning speech representations is to perform pretext task optimization, also known as pre-training. In this approach, representations are learned by solving a task that is derived by the structure of the underlying unlabeled data like for example predicting the next word in a sequence of words or predicting a masked word in a sequence. The advantage of this approach is that it only needs unlabeled data which is of higher availability than labeled data. Within the pretext task optimization approach, the following three learning paradigms can be considered the most widely used:
\begin{enumerate}
    \item \textit{Contrastive learning}: Contrastive learning is based on the idea of understanding the underlying structure and relationships within the data by emphasizing the differences and similarities between different examples of it. This means, a model needs to find representations in the latent space, such that semantically similar samples of the training data have a high similarity in the representation space while semantically dissimilar samples have a low similarity in the representation space. A common training objective is the SimCLR loss~\cite{simclr}: $$\mathcal{L}_\text{SimCLR}^{(i,j)} = - \log\frac{\exp(\text{sim}(\mathbf{z}_i, \mathbf{z}_j) / \tau)}{\sum_{k=1}^{2N} \mathbbb{1}_{[k \neq i]} \exp(\text{sim}(\mathbf{z}_i, \mathbf{z}_k) / \tau)}$$Here, $z_i$ and $z_j$ are similar samples, while $z_i$ and $z_k$ are dissimilar. $sim(\cdot,\cdot)$ is the cosine similarity.
    \item \textit{Generative learning}: In generative learning, an input is reconstructed based on a limited view of it. This can mean predicting the next word in a sequence, a masked word within an input or predicting the original from a noisy input, as can be seen in~\cite{denoising-autoencoder}. An typical training objective is the basic reconstruction, or $L_1$-Loss.
    \item \textit{Predictive learning}: In predictive learning, typically another model is used to compute pseudo labels for the model to train with. An example of this which will be discussed later in more detail is the ``Hidden-Unit BERT'' (HuBERT) model, which initially computes its training targets with the k-means algorithm and later uses intermediate representation of its inner structure as labels.
\end{enumerate}
This paper is structured as follows. First, single-mode speech representation models are introduced, specifically wav2wec2.0 and HuBERT which are the foundation and basis of some of the multi-modal speech representation models. Afterwards, multi-modal speech representation models are shown by first looking at their architecture, then the learning approach and specifics and finally the performance of the models is discussed with respect to other multi-modal and also single-mode models. Finally, a discussion about the impact, advantages and challenges of multi-modal speech representation learning is conducted including a comparison to single mode approaches.
